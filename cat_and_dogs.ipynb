{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o1Vnsf5dIZvM"
      },
      "source": [
        "# Deep Learning Cats and Dogs Project"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4ARipE5BIZvP"
      },
      "outputs": [],
      "source": [
        "import os, shutil\n",
        "\n",
        "#Directory in which we store our dataset\n",
        "original_dataset_dir = './dataset'\n",
        "\n",
        "base_dir = './new_set'\n",
        "#os.mkdir(base_dir)\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import optimizers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3nYUBIT0IZvQ"
      },
      "source": [
        "# Task 1 - Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AcqWkTdaIZvQ"
      },
      "outputs": [],
      "source": [
        "# importing os: The main purpose of the OS module is to interact with the operating system. You can for example use it to create folders, \n",
        "# remove folders, move folders, and sometimes change the working directory.\n",
        "\n",
        "import os, shutil\n",
        "\n",
        "#Create directories and link them together\n",
        "\n",
        "# The os.path.join() function constructs a pathname\n",
        "# os.mkdir is used to make a new directory for train, test and validation splits\n",
        "\n",
        "train_dir = os.path.join(base_dir,'train')\n",
        "#os.mkdir(train_dir)\n",
        "validation_dir = os.path.join(base_dir,'validation')\n",
        "#os.mkdir(validation_dir)\n",
        "test_dir = os.path.join(base_dir,'test')\n",
        "#os.mkdir(test_dir)\n",
        "\n",
        "train_cats_dir = os.path.join(train_dir, 'cats')\n",
        "#os.mkdir(train_cats_dir)\n",
        "train_dogs_dir = os.path.join(train_dir, 'dogs')\n",
        "#os.mkdir(train_dogs_dir)\n",
        "validation_cats_dir = os.path.join(validation_dir, 'cats')\n",
        "#os.mkdir(validation_cats_dir)\n",
        "validation_dogs_dir = os.path.join(validation_dir, 'dogs')\n",
        "#os.mkdir(validation_dogs_dir)\n",
        "test_cats_dir = os.path.join(test_dir, 'cats')\n",
        "#os.mkdir(test_cats_dir)\n",
        "test_dogs_dir = os.path.join(test_dir, 'dogs')\n",
        "#os.mkdir(test_dogs_dir)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "outputs_hidden": true
        },
        "id": "MRBfIFVbIZvR"
      },
      "outputs": [],
      "source": [
        "#We seperate our data in to training, validation and testset\n",
        "\n",
        "# The following commands creates the paths and stores the data: \n",
        "\n",
        "# We have 1500 images of cats and 1500 images of dogs. The 1500 images are split in half to optain \n",
        "# 750 images for training set, the rest of the 750 images are split in half so we optain 375 images for validation \n",
        "# and 375 for test set.\n",
        "\n",
        "\n",
        "fnames = ['cat.{}.jpg'.format(i) for i in range(0,750)]\n",
        "for fname in fnames:\n",
        "    src = os.path. join(original_dataset_dir, fname)\n",
        "    dst = os.path.join(train_cats_dir, fname)\n",
        "    shutil.copyfile(src, dst)\n",
        "    \n",
        "fnames = ['cat.{}.jpg'.format(i) for i in range(750, 1125)]\n",
        "for fname in fnames:\n",
        "    src = os.path. join(original_dataset_dir, fname)\n",
        "    dst = os.path.join(validation_cats_dir, fname)\n",
        "    shutil.copyfile(src, dst)\n",
        "    \n",
        "fnames = ['cat.{}.jpg'.format(i) for i in range(1125, 1500)]\n",
        "for fname in fnames:\n",
        "    src = os.path. join(original_dataset_dir, fname)\n",
        "    dst = os.path.join(test_cats_dir, fname)\n",
        "    shutil.copyfile(src, dst)\n",
        "\n",
        "fnames = ['dog.{}.jpg'.format(i) for i in range(750)]\n",
        "for fname in fnames:\n",
        "    src = os.path. join(original_dataset_dir, fname)\n",
        "    dst = os.path.join(train_dogs_dir, fname)\n",
        "    shutil.copyfile(src, dst)\n",
        "    \n",
        "fnames = ['dog.{}.jpg'.format(i) for i in range(750, 1125)]\n",
        "for fname in fnames:\n",
        "    src = os.path. join(original_dataset_dir, fname)\n",
        "    dst = os.path.join(validation_dogs_dir, fname)\n",
        "    shutil.copyfile(src, dst)\n",
        "    \n",
        "    fnames = ['dog.{}.jpg'.format(i) for i in range(1125, 1500)]\n",
        "for fname in fnames:\n",
        "    src = os.path. join(original_dataset_dir, fname)\n",
        "    dst = os.path.join(test_dogs_dir, fname)\n",
        "    shutil.copyfile(src, dst)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XKYHVAboIZvS",
        "outputId": "5ae482e4-5b28-42bb-a7f0-06411f42ff29"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "total training cat images: 750\n",
            "total training cat images: 750\n",
            "total training cat images: 375\n",
            "total training cat images: 375\n",
            "total training cat images: 375\n",
            "total training cat images: 375\n"
          ]
        }
      ],
      "source": [
        "# The following commands counts how many pictures are in each training split (train/validation/test):\n",
        "print('total training cat images:', len(os.listdir(train_cats_dir)))\n",
        "print('total training dog images:', len(os.listdir(train_dogs_dir)))\n",
        "print('total test cat images:', len(os.listdir(test_cats_dir)))\n",
        "print('total test dog images:', len(os.listdir(test_dogs_dir)))\n",
        "print('total validation cat images:', len(os.listdir(validation_cats_dir)))\n",
        "print('total validation dog images:', len(os.listdir(validation_dogs_dir)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nv9DXaNkIZvT"
      },
      "source": [
        "# Task 3 - Constructing the network"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LAlxDU7BIZvT"
      },
      "source": [
        "### Constructing a neural network:\n",
        "\n",
        "In this step we build the convnet model. The structure of the network is a stack of alternated Conv2D and MaxPooling2D layers. This serves both to augment the capacity of the network and to further reduce the size of the feature maps so they are not overly large when we reach the Flatten layer. A convnet takes as input tensors of shape (image_height, image_width, image_channels). In this case, we’ll configure the convnet to process inputs of size (150, 150, 3). We will do this by passing the argument input_shape=(150, 150, 3) to the first layer. Since the image is in RGB format, the number of channels is set to 3. The output of every Conv2D and MaxPooling2D layer is a 3D tensor of shape (height, width, channels).\n",
        "\n",
        "The hidden layers in our convnet model are generally convolution layers but also pooling layers, which are used to downsample the image. We will be working with MaxPooling. The image contains a lot of pixel values, it is typically easier for the network to learn the features if the image size is reduced. Pooling also helps in avoiding overfitting. Our model switches between a filter size of (2,2) and (3,3) for the pooling layer to obtain a binary output. \n",
        "\n",
        "In each convolution layer, there is a filter of a small size which is moved across the image and performs convolution operations. The operations are element-wise matrix multiplication between the filter values and the pixels in the image. The filter’s values are tuned through the iterative process of training and after a neural net has trained for certain number of epochs, these filters start to look out for various features in the image. We have chosen to use (3,3) as a size of the filters which was the size that gave the best accuracy. \n",
        "\n",
        "We use ReLU function, which is a non-linear activation function and the main advantage of using the ReLU function over other activation functions is that it does not activate all the neurons at the same time. This means that the neurons will only be deactivated if the output of the linear transformation is less than 0.For the negative input values, the result is zero, that means the neuron does not get activated.\n",
        "\n",
        "We have also added one dropout layer before the flatten layer with a dropout rate of 0.5 to prevent overfitting and this was the value with the best accuracy. \n",
        "\n",
        "Since we are dealing with a binary-classification problem, the end of the network will have a single unit (a Dense layer of size 1) and a sigmoid activation. This unit will encode the probability that the network is looking at one class or the other.\n",
        "\n",
        "We compile the model and train it with the optimizer RMSprop and the learning rate 1e-4 as this was the optimizer and value with the best accuracy compared to SDG and adam."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PaFKg9VQIZvU",
        "outputId": "d1b5ff7e-1257-45cb-bca7-6f5f2b5b4715"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_10 (Conv2D)           (None, 148, 148, 64)      1792      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_10 (MaxPooling (None, 74, 74, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_11 (Conv2D)           (None, 74, 74, 64)        36928     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_11 (MaxPooling (None, 24, 24, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_12 (Conv2D)           (None, 24, 24, 128)       73856     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_12 (MaxPooling (None, 12, 12, 128)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_13 (Conv2D)           (None, 12, 12, 128)       147584    \n",
            "_________________________________________________________________\n",
            "max_pooling2d_13 (MaxPooling (None, 6, 6, 128)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_14 (Conv2D)           (None, 6, 6, 256)         295168    \n",
            "_________________________________________________________________\n",
            "max_pooling2d_14 (MaxPooling (None, 2, 2, 256)         0         \n",
            "_________________________________________________________________\n",
            "flatten_2 (Flatten)          (None, 1024)              0         \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 1024)              0         \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 256)               262400    \n",
            "_________________________________________________________________\n",
            "dense_5 (Dense)              (None, 1)                 257       \n",
            "=================================================================\n",
            "Total params: 817,985\n",
            "Trainable params: 817,985\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model = tf.keras.models.Sequential()\n",
        "\n",
        "model.add(tf.keras.layers.Conv2D(64, (3, 3), activation='relu',input_shape=(150, 150, 3)))\n",
        "model.add(tf.keras.layers.MaxPooling2D((2, 2)))\n",
        "model.add(tf.keras.layers.Conv2D(64, (3, 3), activation='relu',padding='same'))\n",
        "model.add(tf.keras.layers.MaxPooling2D((3, 3)))\n",
        "model.add(tf.keras.layers.Conv2D(128, (3, 3), activation='relu',padding='same'))\n",
        "model.add(tf.keras.layers.MaxPooling2D((2, 2)))\n",
        "model.add(tf.keras.layers.Conv2D(128, (3, 3), activation='relu',padding='same'))\n",
        "model.add(tf.keras.layers.MaxPooling2D((2, 2)))\n",
        "model.add(tf.keras.layers.Conv2D(256, (3, 3), activation='relu',padding='same'))\n",
        "model.add(tf.keras.layers.MaxPooling2D((3, 3)))\n",
        "\n",
        "\n",
        "model.add(tf.keras.layers.Flatten())\n",
        "model.add(tf.keras.layers.Dropout(0.5))\n",
        "model.add(tf.keras.layers.Dense(256, activation='relu'))\n",
        "model.add(tf.keras.layers.Dense(1, activation='sigmoid'))\n",
        "\n",
        "model.compile(loss='binary_crossentropy',\n",
        "              optimizer=optimizers.RMSprop(lr=1e-4),\n",
        "              metrics=['acc'])\n",
        "model.summary()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZylKk87zIZvU"
      },
      "source": [
        "# Task 2 - Creating the datagenerators"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7qhK0QA8IZvU"
      },
      "source": [
        "### Training the convnet using dataaugmentation generators\n",
        "In this step we fit the model using image data augmentation via the ImageDataGenerator class and improve the performance of our neural network. The technique artificially creates new training data from existing training data. It involves creating transformed versions of images in the training dataset that belongs to the same class as the original image. Transforms include a range of operations such as shifts, flips, zooms, and much more.\n",
        "\n",
        "We use Keras library which provides the ability to use data augmentation automatically when training a model. This is achieved by using the ImageDataGenerator class. A range of techniques are supported, as well as pixel scaling methods. We will focus on nine main types of data augmentation techniques for image data. We will illustrate one of these in the end."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "56q8APCHIZvV"
      },
      "source": [
        "# Epochs 350"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Gw7uno80IZvV",
        "outputId": "cf132a38-1cb2-4b72-ed1d-d3674564236d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 1500 images belonging to 2 classes.\n",
            "Found 750 images belonging to 2 classes.\n",
            "WARNING:tensorflow:sample_weight modes were coerced from\n",
            "  ...\n",
            "    to  \n",
            "  ['...']\n",
            "WARNING:tensorflow:sample_weight modes were coerced from\n",
            "  ...\n",
            "    to  \n",
            "  ['...']\n",
            "Train for 93 steps, validate for 46 steps\n",
            "Epoch 1/350\n",
            "93/93 [==============================] - 16s 170ms/step - loss: 0.6932 - acc: 0.5108 - val_loss: 0.6915 - val_acc: 0.5122\n",
            "Epoch 2/350\n",
            "93/93 [==============================] - 15s 160ms/step - loss: 0.6896 - acc: 0.5168 - val_loss: 0.6847 - val_acc: 0.5516\n",
            "Epoch 3/350\n",
            "93/93 [==============================] - 15s 158ms/step - loss: 0.6846 - acc: 0.5573 - val_loss: 0.7235 - val_acc: 0.4932\n",
            "Epoch 4/350\n",
            "93/93 [==============================] - 16s 167ms/step - loss: 0.6788 - acc: 0.5573 - val_loss: 0.6747 - val_acc: 0.5380\n",
            "Epoch 5/350\n",
            "93/93 [==============================] - 16s 172ms/step - loss: 0.6693 - acc: 0.5849 - val_loss: 0.6737 - val_acc: 0.5707\n",
            "Epoch 6/350\n",
            "93/93 [==============================] - 17s 179ms/step - loss: 0.6665 - acc: 0.5896 - val_loss: 0.6818 - val_acc: 0.5394\n",
            "Epoch 7/350\n",
            "93/93 [==============================] - 18s 195ms/step - loss: 0.6579 - acc: 0.5991 - val_loss: 0.6783 - val_acc: 0.5462\n",
            "Epoch 8/350\n",
            "93/93 [==============================] - 17s 179ms/step - loss: 0.6556 - acc: 0.6092 - val_loss: 0.7165 - val_acc: 0.5530\n",
            "Epoch 9/350\n",
            "93/93 [==============================] - 15s 159ms/step - loss: 0.6537 - acc: 0.6112 - val_loss: 0.6489 - val_acc: 0.6005\n",
            "Epoch 10/350\n",
            "93/93 [==============================] - 16s 171ms/step - loss: 0.6411 - acc: 0.6287 - val_loss: 0.6835 - val_acc: 0.5774\n",
            "Epoch 11/350\n",
            "93/93 [==============================] - 16s 167ms/step - loss: 0.6364 - acc: 0.6287 - val_loss: 0.6437 - val_acc: 0.6141\n",
            "Epoch 12/350\n",
            "93/93 [==============================] - 17s 186ms/step - loss: 0.6364 - acc: 0.6307 - val_loss: 0.6295 - val_acc: 0.6372\n",
            "Epoch 13/350\n",
            "93/93 [==============================] - 19s 200ms/step - loss: 0.6318 - acc: 0.6348 - val_loss: 0.6239 - val_acc: 0.6359\n",
            "Epoch 14/350\n",
            "93/93 [==============================] - 17s 180ms/step - loss: 0.6309 - acc: 0.6435 - val_loss: 0.7017 - val_acc: 0.5516\n",
            "Epoch 15/350\n",
            "93/93 [==============================] - 17s 184ms/step - loss: 0.6214 - acc: 0.6631 - val_loss: 0.6286 - val_acc: 0.6264\n",
            "Epoch 16/350\n",
            "93/93 [==============================] - 16s 169ms/step - loss: 0.6160 - acc: 0.6523 - val_loss: 0.6120 - val_acc: 0.6481\n",
            "Epoch 17/350\n",
            "93/93 [==============================] - 17s 179ms/step - loss: 0.6113 - acc: 0.6550 - val_loss: 0.6038 - val_acc: 0.6603\n",
            "Epoch 18/350\n",
            "93/93 [==============================] - 15s 162ms/step - loss: 0.6071 - acc: 0.6624 - val_loss: 0.6139 - val_acc: 0.6332\n",
            "Epoch 19/350\n",
            "93/93 [==============================] - 15s 159ms/step - loss: 0.6062 - acc: 0.6691 - val_loss: 0.6078 - val_acc: 0.6739\n",
            "Epoch 20/350\n",
            "93/93 [==============================] - 15s 156ms/step - loss: 0.5965 - acc: 0.6739 - val_loss: 0.6310 - val_acc: 0.6603\n",
            "Epoch 21/350\n",
            "93/93 [==============================] - 14s 151ms/step - loss: 0.5982 - acc: 0.6806 - val_loss: 0.6076 - val_acc: 0.6562\n",
            "Epoch 22/350\n",
            "93/93 [==============================] - 14s 151ms/step - loss: 0.5935 - acc: 0.6772 - val_loss: 0.6089 - val_acc: 0.6576\n",
            "Epoch 23/350\n",
            "93/93 [==============================] - 13s 145ms/step - loss: 0.6027 - acc: 0.6725 - val_loss: 0.5756 - val_acc: 0.7079\n",
            "Epoch 24/350\n",
            "93/93 [==============================] - 14s 151ms/step - loss: 0.5847 - acc: 0.6934 - val_loss: 0.7647 - val_acc: 0.5462\n",
            "Epoch 25/350\n",
            "93/93 [==============================] - 15s 159ms/step - loss: 0.5909 - acc: 0.6894 - val_loss: 0.6365 - val_acc: 0.6399\n",
            "Epoch 26/350\n",
            "93/93 [==============================] - 14s 154ms/step - loss: 0.5861 - acc: 0.6900 - val_loss: 0.5728 - val_acc: 0.6929\n",
            "Epoch 27/350\n",
            "93/93 [==============================] - 14s 155ms/step - loss: 0.5748 - acc: 0.7008 - val_loss: 0.5522 - val_acc: 0.7174\n",
            "Epoch 28/350\n",
            "93/93 [==============================] - 17s 185ms/step - loss: 0.5652 - acc: 0.7096 - val_loss: 0.5632 - val_acc: 0.7024\n",
            "Epoch 29/350\n",
            "93/93 [==============================] - 17s 187ms/step - loss: 0.5791 - acc: 0.6968 - val_loss: 0.5562 - val_acc: 0.7242\n",
            "Epoch 30/350\n",
            "93/93 [==============================] - 16s 171ms/step - loss: 0.5798 - acc: 0.7042 - val_loss: 0.5707 - val_acc: 0.7038\n",
            "Epoch 31/350\n",
            "93/93 [==============================] - 16s 175ms/step - loss: 0.5809 - acc: 0.6961 - val_loss: 0.5496 - val_acc: 0.7255\n",
            "Epoch 32/350\n",
            "93/93 [==============================] - 16s 177ms/step - loss: 0.5545 - acc: 0.7129 - val_loss: 0.6118 - val_acc: 0.6617\n",
            "Epoch 33/350\n",
            "93/93 [==============================] - 16s 167ms/step - loss: 0.5538 - acc: 0.7244 - val_loss: 0.5374 - val_acc: 0.7283\n",
            "Epoch 34/350\n",
            "93/93 [==============================] - 16s 169ms/step - loss: 0.5590 - acc: 0.7170 - val_loss: 0.5417 - val_acc: 0.7242\n",
            "Epoch 35/350\n",
            "93/93 [==============================] - 16s 177ms/step - loss: 0.5396 - acc: 0.7412 - val_loss: 0.5711 - val_acc: 0.6902\n",
            "Epoch 36/350\n",
            "93/93 [==============================] - 16s 174ms/step - loss: 0.5378 - acc: 0.7298 - val_loss: 0.5567 - val_acc: 0.7174\n",
            "Epoch 37/350\n",
            "93/93 [==============================] - 15s 162ms/step - loss: 0.5408 - acc: 0.7298 - val_loss: 0.5414 - val_acc: 0.7310\n",
            "Epoch 38/350\n",
            "93/93 [==============================] - 15s 164ms/step - loss: 0.5415 - acc: 0.7224 - val_loss: 0.6547 - val_acc: 0.6399\n",
            "Epoch 39/350\n",
            "93/93 [==============================] - 15s 159ms/step - loss: 0.5439 - acc: 0.7183 - val_loss: 0.5513 - val_acc: 0.7255\n",
            "Epoch 40/350\n",
            "93/93 [==============================] - 14s 155ms/step - loss: 0.5373 - acc: 0.7345 - val_loss: 0.6746 - val_acc: 0.6345\n",
            "Epoch 41/350\n",
            "93/93 [==============================] - 15s 158ms/step - loss: 0.5405 - acc: 0.7257 - val_loss: 0.5273 - val_acc: 0.7405\n",
            "Epoch 42/350\n",
            "93/93 [==============================] - 14s 149ms/step - loss: 0.5352 - acc: 0.7345 - val_loss: 0.5757 - val_acc: 0.6984\n",
            "Epoch 43/350\n",
            "93/93 [==============================] - 14s 147ms/step - loss: 0.5216 - acc: 0.7534 - val_loss: 0.5122 - val_acc: 0.7391\n",
            "Epoch 44/350\n",
            "93/93 [==============================] - 14s 153ms/step - loss: 0.5292 - acc: 0.7338 - val_loss: 0.5976 - val_acc: 0.6576\n",
            "Epoch 45/350\n",
            "93/93 [==============================] - 15s 159ms/step - loss: 0.5322 - acc: 0.7311 - val_loss: 0.7500 - val_acc: 0.6386\n",
            "Epoch 46/350\n",
            "93/93 [==============================] - 15s 157ms/step - loss: 0.5201 - acc: 0.7332 - val_loss: 0.5344 - val_acc: 0.7391\n",
            "Epoch 47/350\n",
            "93/93 [==============================] - 14s 152ms/step - loss: 0.5337 - acc: 0.7318 - val_loss: 0.5126 - val_acc: 0.7514\n",
            "Epoch 48/350\n",
            "93/93 [==============================] - 14s 153ms/step - loss: 0.5183 - acc: 0.7513 - val_loss: 0.5154 - val_acc: 0.7269\n",
            "Epoch 49/350\n",
            "93/93 [==============================] - 15s 157ms/step - loss: 0.5019 - acc: 0.7642 - val_loss: 0.5982 - val_acc: 0.7133\n",
            "Epoch 50/350\n",
            "93/93 [==============================] - 14s 154ms/step - loss: 0.5241 - acc: 0.7385 - val_loss: 0.6613 - val_acc: 0.6726\n",
            "Epoch 51/350\n",
            "93/93 [==============================] - 14s 149ms/step - loss: 0.5204 - acc: 0.7473 - val_loss: 0.6078 - val_acc: 0.6984\n",
            "Epoch 52/350\n",
            "93/93 [==============================] - 15s 160ms/step - loss: 0.5177 - acc: 0.7446 - val_loss: 0.4814 - val_acc: 0.7582\n",
            "Epoch 53/350\n",
            "93/93 [==============================] - 15s 159ms/step - loss: 0.5038 - acc: 0.7500 - val_loss: 0.5603 - val_acc: 0.7296\n",
            "Epoch 54/350\n",
            "93/93 [==============================] - 14s 153ms/step - loss: 0.5057 - acc: 0.7561 - val_loss: 0.4922 - val_acc: 0.7432\n",
            "Epoch 55/350\n",
            "93/93 [==============================] - 15s 159ms/step - loss: 0.4952 - acc: 0.7534 - val_loss: 0.5065 - val_acc: 0.7473\n",
            "Epoch 56/350\n",
            "93/93 [==============================] - 15s 159ms/step - loss: 0.5036 - acc: 0.7513 - val_loss: 0.5533 - val_acc: 0.7174\n",
            "Epoch 57/350\n",
            "93/93 [==============================] - 15s 157ms/step - loss: 0.5011 - acc: 0.7655 - val_loss: 0.6747 - val_acc: 0.6685\n",
            "Epoch 58/350\n",
            "93/93 [==============================] - 15s 156ms/step - loss: 0.4957 - acc: 0.7594 - val_loss: 0.5475 - val_acc: 0.7418\n",
            "Epoch 59/350\n",
            "93/93 [==============================] - 16s 170ms/step - loss: 0.4965 - acc: 0.7581 - val_loss: 0.5200 - val_acc: 0.7459\n",
            "Epoch 60/350\n",
            "93/93 [==============================] - 16s 171ms/step - loss: 0.4828 - acc: 0.7682 - val_loss: 0.5382 - val_acc: 0.7486\n",
            "Epoch 61/350\n",
            "93/93 [==============================] - 16s 175ms/step - loss: 0.4685 - acc: 0.7830 - val_loss: 0.4945 - val_acc: 0.7514\n",
            "Epoch 62/350\n",
            "93/93 [==============================] - 16s 168ms/step - loss: 0.4971 - acc: 0.7689 - val_loss: 0.4915 - val_acc: 0.7622\n",
            "Epoch 63/350\n",
            "93/93 [==============================] - 14s 156ms/step - loss: 0.4897 - acc: 0.7689 - val_loss: 0.5152 - val_acc: 0.7337\n",
            "Epoch 64/350\n",
            "93/93 [==============================] - 15s 165ms/step - loss: 0.4768 - acc: 0.7642 - val_loss: 0.5087 - val_acc: 0.7446\n",
            "Epoch 65/350\n",
            "93/93 [==============================] - 14s 154ms/step - loss: 0.4983 - acc: 0.7487 - val_loss: 0.5028 - val_acc: 0.7459\n",
            "Epoch 66/350\n",
            "93/93 [==============================] - 15s 165ms/step - loss: 0.4702 - acc: 0.7776 - val_loss: 0.5924 - val_acc: 0.7269\n",
            "Epoch 67/350\n",
            "93/93 [==============================] - 15s 159ms/step - loss: 0.4883 - acc: 0.7722 - val_loss: 0.5264 - val_acc: 0.7228\n",
            "Epoch 68/350\n",
            "93/93 [==============================] - 15s 159ms/step - loss: 0.4803 - acc: 0.7823 - val_loss: 0.4915 - val_acc: 0.7649\n",
            "Epoch 69/350\n",
            "93/93 [==============================] - 15s 160ms/step - loss: 0.4808 - acc: 0.7709 - val_loss: 0.4747 - val_acc: 0.7677\n",
            "Epoch 70/350\n",
            "93/93 [==============================] - 16s 171ms/step - loss: 0.4523 - acc: 0.7970 - val_loss: 0.5302 - val_acc: 0.7731\n",
            "Epoch 71/350\n",
            "93/93 [==============================] - 16s 167ms/step - loss: 0.4772 - acc: 0.7682 - val_loss: 0.4929 - val_acc: 0.7514\n",
            "Epoch 72/350\n",
            "93/93 [==============================] - 16s 171ms/step - loss: 0.4607 - acc: 0.7898 - val_loss: 0.5709 - val_acc: 0.7418\n",
            "Epoch 73/350\n",
            "93/93 [==============================] - 16s 168ms/step - loss: 0.4592 - acc: 0.7817 - val_loss: 0.6575 - val_acc: 0.7160\n",
            "Epoch 74/350\n",
            "93/93 [==============================] - 15s 162ms/step - loss: 0.4742 - acc: 0.7770 - val_loss: 0.5010 - val_acc: 0.7595\n",
            "Epoch 75/350\n",
            "93/93 [==============================] - 16s 168ms/step - loss: 0.4671 - acc: 0.7837 - val_loss: 0.6281 - val_acc: 0.6875\n",
            "Epoch 76/350\n",
            "93/93 [==============================] - 16s 177ms/step - loss: 0.4543 - acc: 0.7891 - val_loss: 0.5344 - val_acc: 0.7283\n",
            "Epoch 77/350\n",
            "93/93 [==============================] - 16s 169ms/step - loss: 0.4638 - acc: 0.7863 - val_loss: 0.5041 - val_acc: 0.7582\n",
            "Epoch 78/350\n",
            "93/93 [==============================] - 16s 173ms/step - loss: 0.4365 - acc: 0.8073 - val_loss: 0.4954 - val_acc: 0.7636\n",
            "Epoch 79/350\n",
            "93/93 [==============================] - 16s 170ms/step - loss: 0.4547 - acc: 0.7837 - val_loss: 0.4826 - val_acc: 0.7663\n",
            "Epoch 80/350\n",
            "93/93 [==============================] - 16s 174ms/step - loss: 0.4506 - acc: 0.7844 - val_loss: 0.4628 - val_acc: 0.7894\n",
            "Epoch 81/350\n",
            "93/93 [==============================] - 16s 171ms/step - loss: 0.4380 - acc: 0.8032 - val_loss: 0.5607 - val_acc: 0.7310\n",
            "Epoch 82/350\n",
            "93/93 [==============================] - 15s 162ms/step - loss: 0.4609 - acc: 0.7945 - val_loss: 0.4924 - val_acc: 0.7582\n",
            "Epoch 83/350\n",
            "93/93 [==============================] - 16s 168ms/step - loss: 0.4454 - acc: 0.8024 - val_loss: 0.4659 - val_acc: 0.7758\n",
            "Epoch 84/350\n",
            "93/93 [==============================] - 16s 169ms/step - loss: 0.4346 - acc: 0.8086 - val_loss: 0.4823 - val_acc: 0.7582\n",
            "Epoch 85/350\n",
            "93/93 [==============================] - 15s 165ms/step - loss: 0.4436 - acc: 0.7891 - val_loss: 0.5106 - val_acc: 0.7704\n",
            "Epoch 86/350\n",
            "93/93 [==============================] - 16s 176ms/step - loss: 0.4193 - acc: 0.8100 - val_loss: 0.5290 - val_acc: 0.7649\n",
            "Epoch 87/350\n",
            "93/93 [==============================] - 17s 184ms/step - loss: 0.4327 - acc: 0.7999 - val_loss: 0.5686 - val_acc: 0.7486\n",
            "Epoch 88/350\n",
            "93/93 [==============================] - 15s 166ms/step - loss: 0.4362 - acc: 0.7945 - val_loss: 0.4885 - val_acc: 0.7758\n",
            "Epoch 89/350\n",
            "93/93 [==============================] - 16s 171ms/step - loss: 0.4413 - acc: 0.7911 - val_loss: 0.5177 - val_acc: 0.7812\n",
            "Epoch 90/350\n",
            "93/93 [==============================] - 16s 170ms/step - loss: 0.4177 - acc: 0.8053 - val_loss: 0.4744 - val_acc: 0.7636\n",
            "Epoch 91/350\n",
            "93/93 [==============================] - 15s 162ms/step - loss: 0.4389 - acc: 0.8086 - val_loss: 0.4603 - val_acc: 0.8030\n",
            "Epoch 92/350\n",
            "93/93 [==============================] - 16s 168ms/step - loss: 0.4245 - acc: 0.8073 - val_loss: 0.4684 - val_acc: 0.7894\n",
            "Epoch 93/350\n",
            "93/93 [==============================] - 15s 159ms/step - loss: 0.4288 - acc: 0.8080 - val_loss: 0.4890 - val_acc: 0.7717\n",
            "Epoch 94/350\n",
            "93/93 [==============================] - 15s 163ms/step - loss: 0.4346 - acc: 0.8053 - val_loss: 0.4640 - val_acc: 0.7908\n",
            "Epoch 95/350\n",
            "93/93 [==============================] - 15s 161ms/step - loss: 0.4196 - acc: 0.8080 - val_loss: 0.7285 - val_acc: 0.7147\n",
            "Epoch 96/350\n",
            "93/93 [==============================] - 16s 174ms/step - loss: 0.4151 - acc: 0.8100 - val_loss: 0.4304 - val_acc: 0.7908\n",
            "Epoch 97/350\n",
            "93/93 [==============================] - 17s 178ms/step - loss: 0.4039 - acc: 0.8235 - val_loss: 0.7927 - val_acc: 0.6413\n",
            "Epoch 98/350\n",
            "93/93 [==============================] - 18s 193ms/step - loss: 0.4023 - acc: 0.8214 - val_loss: 0.4693 - val_acc: 0.8003\n",
            "Epoch 99/350\n",
            "93/93 [==============================] - 15s 165ms/step - loss: 0.4163 - acc: 0.8106 - val_loss: 0.4738 - val_acc: 0.7799\n",
            "Epoch 100/350\n",
            "93/93 [==============================] - 16s 173ms/step - loss: 0.4190 - acc: 0.8080 - val_loss: 0.4596 - val_acc: 0.7731\n",
            "Epoch 101/350\n",
            "93/93 [==============================] - 14s 152ms/step - loss: 0.3965 - acc: 0.8181 - val_loss: 0.4814 - val_acc: 0.7799\n",
            "Epoch 102/350\n",
            "93/93 [==============================] - 15s 162ms/step - loss: 0.4124 - acc: 0.8192 - val_loss: 0.4925 - val_acc: 0.7568\n",
            "Epoch 103/350\n",
            "93/93 [==============================] - 18s 194ms/step - loss: 0.4013 - acc: 0.8160 - val_loss: 0.4561 - val_acc: 0.7908\n",
            "Epoch 104/350\n",
            "93/93 [==============================] - 15s 157ms/step - loss: 0.3918 - acc: 0.8356 - val_loss: 0.5535 - val_acc: 0.7486\n",
            "Epoch 105/350\n",
            "93/93 [==============================] - 15s 159ms/step - loss: 0.4009 - acc: 0.8268 - val_loss: 0.5345 - val_acc: 0.7351\n",
            "Epoch 106/350\n",
            "93/93 [==============================] - 16s 171ms/step - loss: 0.3907 - acc: 0.8416 - val_loss: 0.5280 - val_acc: 0.7568\n",
            "Epoch 107/350\n",
            "93/93 [==============================] - 15s 165ms/step - loss: 0.3971 - acc: 0.8255 - val_loss: 0.4887 - val_acc: 0.7799\n",
            "Epoch 108/350\n",
            "93/93 [==============================] - 15s 161ms/step - loss: 0.3752 - acc: 0.8315 - val_loss: 0.4631 - val_acc: 0.7758\n",
            "Epoch 109/350\n",
            "93/93 [==============================] - 16s 168ms/step - loss: 0.3969 - acc: 0.8261 - val_loss: 0.4685 - val_acc: 0.7717\n",
            "Epoch 110/350\n",
            "93/93 [==============================] - 15s 162ms/step - loss: 0.3952 - acc: 0.8241 - val_loss: 0.4638 - val_acc: 0.7745\n",
            "Epoch 111/350\n",
            "93/93 [==============================] - 15s 161ms/step - loss: 0.3794 - acc: 0.8329 - val_loss: 0.4796 - val_acc: 0.8030\n",
            "Epoch 112/350\n",
            "93/93 [==============================] - 16s 168ms/step - loss: 0.3760 - acc: 0.8315 - val_loss: 0.4570 - val_acc: 0.8016\n",
            "Epoch 113/350\n",
            "93/93 [==============================] - 15s 163ms/step - loss: 0.3671 - acc: 0.8484 - val_loss: 0.4427 - val_acc: 0.8071\n",
            "Epoch 114/350\n",
            "93/93 [==============================] - 15s 166ms/step - loss: 0.3896 - acc: 0.8369 - val_loss: 0.4277 - val_acc: 0.8084\n",
            "Epoch 115/350\n",
            "93/93 [==============================] - 14s 155ms/step - loss: 0.3687 - acc: 0.8416 - val_loss: 0.4706 - val_acc: 0.8030\n",
            "Epoch 116/350\n",
            "93/93 [==============================] - 14s 151ms/step - loss: 0.3737 - acc: 0.8295 - val_loss: 0.4112 - val_acc: 0.8071\n",
            "Epoch 117/350\n",
            "93/93 [==============================] - 14s 155ms/step - loss: 0.3847 - acc: 0.8295 - val_loss: 0.4634 - val_acc: 0.7894\n",
            "Epoch 118/350\n",
            "93/93 [==============================] - 15s 163ms/step - loss: 0.3723 - acc: 0.8416 - val_loss: 0.5975 - val_acc: 0.7514\n",
            "Epoch 119/350\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "93/93 [==============================] - 14s 154ms/step - loss: 0.3823 - acc: 0.8255 - val_loss: 0.4138 - val_acc: 0.8179\n",
            "Epoch 120/350\n",
            "93/93 [==============================] - 15s 161ms/step - loss: 0.3681 - acc: 0.8356 - val_loss: 0.4539 - val_acc: 0.7921\n",
            "Epoch 121/350\n",
            "93/93 [==============================] - 14s 156ms/step - loss: 0.3612 - acc: 0.8430 - val_loss: 0.5176 - val_acc: 0.7976\n",
            "Epoch 122/350\n",
            "93/93 [==============================] - 15s 159ms/step - loss: 0.3589 - acc: 0.8450 - val_loss: 0.4372 - val_acc: 0.8098\n",
            "Epoch 123/350\n",
            "93/93 [==============================] - 15s 159ms/step - loss: 0.3626 - acc: 0.8484 - val_loss: 0.4273 - val_acc: 0.8111\n",
            "Epoch 124/350\n",
            "93/93 [==============================] - 15s 165ms/step - loss: 0.3476 - acc: 0.8592 - val_loss: 0.4439 - val_acc: 0.8016\n",
            "Epoch 125/350\n",
            "93/93 [==============================] - 16s 169ms/step - loss: 0.3609 - acc: 0.8376 - val_loss: 0.4466 - val_acc: 0.8139\n",
            "Epoch 126/350\n",
            "93/93 [==============================] - 15s 166ms/step - loss: 0.3562 - acc: 0.8430 - val_loss: 0.4505 - val_acc: 0.7976\n",
            "Epoch 127/350\n",
            "93/93 [==============================] - 15s 160ms/step - loss: 0.3330 - acc: 0.8511 - val_loss: 0.4909 - val_acc: 0.8030\n",
            "Epoch 128/350\n",
            "93/93 [==============================] - 15s 160ms/step - loss: 0.3621 - acc: 0.8342 - val_loss: 0.4121 - val_acc: 0.8274\n",
            "Epoch 129/350\n",
            "93/93 [==============================] - 15s 162ms/step - loss: 0.3574 - acc: 0.8504 - val_loss: 0.6437 - val_acc: 0.7432\n",
            "Epoch 130/350\n",
            "93/93 [==============================] - 15s 158ms/step - loss: 0.3663 - acc: 0.8416 - val_loss: 0.4135 - val_acc: 0.8247\n",
            "Epoch 131/350\n",
            "93/93 [==============================] - 15s 162ms/step - loss: 0.3640 - acc: 0.8336 - val_loss: 0.4866 - val_acc: 0.7962\n",
            "Epoch 132/350\n",
            "93/93 [==============================] - 15s 157ms/step - loss: 0.3548 - acc: 0.8497 - val_loss: 0.4557 - val_acc: 0.7948\n",
            "Epoch 133/350\n",
            "93/93 [==============================] - 14s 153ms/step - loss: 0.3684 - acc: 0.8511 - val_loss: 0.4188 - val_acc: 0.8057\n",
            "Epoch 134/350\n",
            "93/93 [==============================] - 16s 168ms/step - loss: 0.3619 - acc: 0.8457 - val_loss: 0.4046 - val_acc: 0.8288\n",
            "Epoch 135/350\n",
            "93/93 [==============================] - 15s 166ms/step - loss: 0.3361 - acc: 0.8659 - val_loss: 0.3966 - val_acc: 0.8288\n",
            "Epoch 136/350\n",
            "93/93 [==============================] - 15s 157ms/step - loss: 0.3329 - acc: 0.8504 - val_loss: 0.4399 - val_acc: 0.8166\n",
            "Epoch 137/350\n",
            "93/93 [==============================] - 15s 157ms/step - loss: 0.3531 - acc: 0.8571 - val_loss: 0.3961 - val_acc: 0.8166\n",
            "Epoch 138/350\n",
            "93/93 [==============================] - 15s 159ms/step - loss: 0.3398 - acc: 0.8551 - val_loss: 0.4867 - val_acc: 0.7921\n",
            "Epoch 139/350\n",
            "93/93 [==============================] - 16s 170ms/step - loss: 0.3315 - acc: 0.8659 - val_loss: 0.3888 - val_acc: 0.8370\n",
            "Epoch 140/350\n",
            "93/93 [==============================] - 15s 163ms/step - loss: 0.3444 - acc: 0.8524 - val_loss: 0.4042 - val_acc: 0.8274\n",
            "Epoch 141/350\n",
            "93/93 [==============================] - 15s 162ms/step - loss: 0.3354 - acc: 0.8551 - val_loss: 0.4338 - val_acc: 0.8111\n",
            "Epoch 142/350\n",
            "93/93 [==============================] - 15s 164ms/step - loss: 0.3401 - acc: 0.8551 - val_loss: 0.8880 - val_acc: 0.7323\n",
            "Epoch 143/350\n",
            "93/93 [==============================] - 15s 160ms/step - loss: 0.3263 - acc: 0.8652 - val_loss: 0.4266 - val_acc: 0.8261\n",
            "Epoch 144/350\n",
            "93/93 [==============================] - 14s 155ms/step - loss: 0.3284 - acc: 0.8625 - val_loss: 0.3930 - val_acc: 0.8274\n",
            "Epoch 145/350\n",
            "93/93 [==============================] - 15s 157ms/step - loss: 0.3027 - acc: 0.8713 - val_loss: 0.4378 - val_acc: 0.8125\n",
            "Epoch 146/350\n",
            "93/93 [==============================] - 15s 158ms/step - loss: 0.3131 - acc: 0.8699 - val_loss: 0.4969 - val_acc: 0.8098\n",
            "Epoch 147/350\n",
            "93/93 [==============================] - 14s 156ms/step - loss: 0.3215 - acc: 0.8659 - val_loss: 0.3860 - val_acc: 0.8424\n",
            "Epoch 148/350\n",
            "93/93 [==============================] - 15s 162ms/step - loss: 0.3362 - acc: 0.8538 - val_loss: 0.4221 - val_acc: 0.8057\n",
            "Epoch 149/350\n",
            "93/93 [==============================] - 17s 180ms/step - loss: 0.3173 - acc: 0.8679 - val_loss: 0.4088 - val_acc: 0.8207\n",
            "Epoch 150/350\n",
            "93/93 [==============================] - 19s 206ms/step - loss: 0.3019 - acc: 0.8753 - val_loss: 0.4648 - val_acc: 0.8111\n",
            "Epoch 151/350\n",
            "93/93 [==============================] - 19s 201ms/step - loss: 0.3258 - acc: 0.8531 - val_loss: 0.3905 - val_acc: 0.8410\n",
            "Epoch 152/350\n",
            "93/93 [==============================] - 17s 181ms/step - loss: 0.3271 - acc: 0.8565 - val_loss: 0.3968 - val_acc: 0.8302\n",
            "Epoch 153/350\n",
            "93/93 [==============================] - 15s 159ms/step - loss: 0.3135 - acc: 0.8605 - val_loss: 0.4211 - val_acc: 0.8410\n",
            "Epoch 154/350\n",
            "93/93 [==============================] - 16s 172ms/step - loss: 0.3258 - acc: 0.8669 - val_loss: 0.3979 - val_acc: 0.8247\n",
            "Epoch 155/350\n",
            "93/93 [==============================] - 15s 160ms/step - loss: 0.3006 - acc: 0.8774 - val_loss: 0.4133 - val_acc: 0.8302\n",
            "Epoch 156/350\n",
            "93/93 [==============================] - 15s 164ms/step - loss: 0.3110 - acc: 0.8706 - val_loss: 0.3849 - val_acc: 0.8302\n",
            "Epoch 157/350\n",
            "93/93 [==============================] - 15s 165ms/step - loss: 0.3143 - acc: 0.8713 - val_loss: 0.5313 - val_acc: 0.7921\n",
            "Epoch 158/350\n",
            "93/93 [==============================] - 15s 164ms/step - loss: 0.2958 - acc: 0.8693 - val_loss: 0.5770 - val_acc: 0.7894\n",
            "Epoch 159/350\n",
            "93/93 [==============================] - 15s 158ms/step - loss: 0.3028 - acc: 0.8807 - val_loss: 0.4032 - val_acc: 0.8410\n",
            "Epoch 160/350\n",
            "93/93 [==============================] - 15s 166ms/step - loss: 0.3193 - acc: 0.8679 - val_loss: 0.3652 - val_acc: 0.8438\n",
            "Epoch 161/350\n",
            "93/93 [==============================] - 15s 159ms/step - loss: 0.2987 - acc: 0.8706 - val_loss: 0.4774 - val_acc: 0.7894\n",
            "Epoch 162/350\n",
            "93/93 [==============================] - 15s 156ms/step - loss: 0.3200 - acc: 0.8632 - val_loss: 0.5505 - val_acc: 0.7989\n",
            "Epoch 163/350\n",
            "93/93 [==============================] - 15s 160ms/step - loss: 0.2975 - acc: 0.8760 - val_loss: 0.5897 - val_acc: 0.7595\n",
            "Epoch 164/350\n",
            "93/93 [==============================] - 15s 163ms/step - loss: 0.3180 - acc: 0.8632 - val_loss: 0.4397 - val_acc: 0.8288\n",
            "Epoch 165/350\n",
            "93/93 [==============================] - 16s 170ms/step - loss: 0.3146 - acc: 0.8632 - val_loss: 0.4286 - val_acc: 0.8179\n",
            "Epoch 166/350\n",
            "93/93 [==============================] - 16s 168ms/step - loss: 0.2978 - acc: 0.8693 - val_loss: 0.4077 - val_acc: 0.8329\n",
            "Epoch 167/350\n",
            "93/93 [==============================] - 15s 156ms/step - loss: 0.3033 - acc: 0.8706 - val_loss: 0.4019 - val_acc: 0.8315\n",
            "Epoch 168/350\n",
            "93/93 [==============================] - 15s 160ms/step - loss: 0.2854 - acc: 0.8902 - val_loss: 0.3806 - val_acc: 0.8329\n",
            "Epoch 169/350\n",
            "93/93 [==============================] - 14s 153ms/step - loss: 0.2711 - acc: 0.8861 - val_loss: 0.4126 - val_acc: 0.8315\n",
            "Epoch 170/350\n",
            "93/93 [==============================] - 14s 154ms/step - loss: 0.2914 - acc: 0.8693 - val_loss: 0.4533 - val_acc: 0.8370\n",
            "Epoch 171/350\n",
            "93/93 [==============================] - 14s 154ms/step - loss: 0.3074 - acc: 0.8774 - val_loss: 0.6080 - val_acc: 0.7812\n",
            "Epoch 172/350\n",
            "93/93 [==============================] - 15s 156ms/step - loss: 0.2837 - acc: 0.8841 - val_loss: 0.4404 - val_acc: 0.8261\n",
            "Epoch 173/350\n",
            "93/93 [==============================] - 14s 149ms/step - loss: 0.2761 - acc: 0.8814 - val_loss: 0.4079 - val_acc: 0.8410\n",
            "Epoch 174/350\n",
            "93/93 [==============================] - 14s 154ms/step - loss: 0.3003 - acc: 0.8814 - val_loss: 0.6017 - val_acc: 0.7853\n",
            "Epoch 175/350\n",
            "93/93 [==============================] - 15s 162ms/step - loss: 0.2732 - acc: 0.8895 - val_loss: 0.4970 - val_acc: 0.8247\n",
            "Epoch 176/350\n",
            "93/93 [==============================] - 15s 166ms/step - loss: 0.2849 - acc: 0.8827 - val_loss: 0.4184 - val_acc: 0.8220\n",
            "Epoch 177/350\n",
            "93/93 [==============================] - 15s 163ms/step - loss: 0.2711 - acc: 0.8841 - val_loss: 0.3769 - val_acc: 0.8302\n",
            "Epoch 178/350\n",
            "93/93 [==============================] - 15s 159ms/step - loss: 0.2908 - acc: 0.8787 - val_loss: 0.7250 - val_acc: 0.7432\n",
            "Epoch 179/350\n",
            "93/93 [==============================] - 16s 171ms/step - loss: 0.2792 - acc: 0.8888 - val_loss: 0.3892 - val_acc: 0.8288\n",
            "Epoch 180/350\n",
            "93/93 [==============================] - 15s 166ms/step - loss: 0.2821 - acc: 0.8821 - val_loss: 0.3806 - val_acc: 0.8560\n",
            "Epoch 181/350\n",
            "93/93 [==============================] - 16s 167ms/step - loss: 0.2779 - acc: 0.8888 - val_loss: 0.3975 - val_acc: 0.8478\n",
            "Epoch 182/350\n",
            "93/93 [==============================] - 15s 165ms/step - loss: 0.2847 - acc: 0.8780 - val_loss: 0.4551 - val_acc: 0.8383\n",
            "Epoch 183/350\n",
            "93/93 [==============================] - 15s 161ms/step - loss: 0.2887 - acc: 0.8814 - val_loss: 0.4922 - val_acc: 0.8234\n",
            "Epoch 184/350\n",
            "93/93 [==============================] - 16s 171ms/step - loss: 0.2888 - acc: 0.8801 - val_loss: 0.3914 - val_acc: 0.8247\n",
            "Epoch 185/350\n",
            "93/93 [==============================] - 15s 165ms/step - loss: 0.2762 - acc: 0.8848 - val_loss: 0.6437 - val_acc: 0.7867\n",
            "Epoch 186/350\n",
            "93/93 [==============================] - 15s 164ms/step - loss: 0.2776 - acc: 0.8821 - val_loss: 0.4752 - val_acc: 0.8071\n",
            "Epoch 187/350\n",
            "93/93 [==============================] - 16s 174ms/step - loss: 0.2849 - acc: 0.8908 - val_loss: 0.5169 - val_acc: 0.8152\n",
            "Epoch 188/350\n",
            "93/93 [==============================] - 16s 175ms/step - loss: 0.2706 - acc: 0.8908 - val_loss: 0.5287 - val_acc: 0.8152\n",
            "Epoch 189/350\n",
            "93/93 [==============================] - 16s 170ms/step - loss: 0.2889 - acc: 0.8814 - val_loss: 0.4381 - val_acc: 0.8424\n",
            "Epoch 190/350\n",
            "93/93 [==============================] - 17s 186ms/step - loss: 0.2476 - acc: 0.8989 - val_loss: 0.4261 - val_acc: 0.8492\n",
            "Epoch 191/350\n",
            "93/93 [==============================] - 16s 172ms/step - loss: 0.2675 - acc: 0.8908 - val_loss: 0.3688 - val_acc: 0.8492\n",
            "Epoch 192/350\n",
            "93/93 [==============================] - 15s 166ms/step - loss: 0.2744 - acc: 0.8976 - val_loss: 0.3675 - val_acc: 0.8505\n",
            "Epoch 193/350\n",
            "93/93 [==============================] - 16s 175ms/step - loss: 0.2735 - acc: 0.8801 - val_loss: 0.5339 - val_acc: 0.8234\n",
            "Epoch 194/350\n",
            "93/93 [==============================] - 16s 175ms/step - loss: 0.2753 - acc: 0.8834 - val_loss: 0.3999 - val_acc: 0.8505\n",
            "Epoch 195/350\n",
            "93/93 [==============================] - 16s 171ms/step - loss: 0.2711 - acc: 0.8868 - val_loss: 0.5078 - val_acc: 0.8220\n",
            "Epoch 196/350\n",
            "93/93 [==============================] - 16s 167ms/step - loss: 0.2701 - acc: 0.8814 - val_loss: 0.4409 - val_acc: 0.8247\n",
            "Epoch 197/350\n",
            "93/93 [==============================] - 17s 181ms/step - loss: 0.2622 - acc: 0.8962 - val_loss: 0.3545 - val_acc: 0.8383\n",
            "Epoch 198/350\n",
            "93/93 [==============================] - 16s 168ms/step - loss: 0.2590 - acc: 0.8801 - val_loss: 0.4913 - val_acc: 0.8193\n",
            "Epoch 199/350\n",
            "93/93 [==============================] - 16s 169ms/step - loss: 0.2606 - acc: 0.8935 - val_loss: 0.4079 - val_acc: 0.8492\n",
            "Epoch 200/350\n",
            "93/93 [==============================] - 16s 170ms/step - loss: 0.2544 - acc: 0.8976 - val_loss: 0.4327 - val_acc: 0.8247\n",
            "Epoch 201/350\n",
            "93/93 [==============================] - 15s 163ms/step - loss: 0.2418 - acc: 0.8989 - val_loss: 0.4047 - val_acc: 0.8601\n",
            "Epoch 202/350\n",
            "93/93 [==============================] - 15s 164ms/step - loss: 0.2730 - acc: 0.8868 - val_loss: 0.3730 - val_acc: 0.8424\n",
            "Epoch 203/350\n",
            "93/93 [==============================] - 15s 164ms/step - loss: 0.2271 - acc: 0.9009 - val_loss: 0.5378 - val_acc: 0.8274\n",
            "Epoch 204/350\n",
            "93/93 [==============================] - 16s 169ms/step - loss: 0.2302 - acc: 0.9097 - val_loss: 0.6639 - val_acc: 0.7894\n",
            "Epoch 205/350\n",
            "93/93 [==============================] - 16s 168ms/step - loss: 0.2398 - acc: 0.8989 - val_loss: 0.4526 - val_acc: 0.8370\n",
            "Epoch 206/350\n",
            "93/93 [==============================] - 15s 160ms/step - loss: 0.2506 - acc: 0.8935 - val_loss: 0.4825 - val_acc: 0.8397\n",
            "Epoch 207/350\n",
            "93/93 [==============================] - 15s 162ms/step - loss: 0.2663 - acc: 0.8902 - val_loss: 0.5338 - val_acc: 0.8179\n",
            "Epoch 208/350\n",
            "93/93 [==============================] - 15s 158ms/step - loss: 0.2653 - acc: 0.8875 - val_loss: 0.4435 - val_acc: 0.8451\n",
            "Epoch 209/350\n",
            "93/93 [==============================] - 15s 158ms/step - loss: 0.2436 - acc: 0.9003 - val_loss: 0.7120 - val_acc: 0.7690\n",
            "Epoch 210/350\n",
            "93/93 [==============================] - 15s 162ms/step - loss: 0.2726 - acc: 0.8841 - val_loss: 0.4492 - val_acc: 0.8315\n",
            "Epoch 211/350\n",
            "93/93 [==============================] - 14s 153ms/step - loss: 0.2405 - acc: 0.9003 - val_loss: 1.0134 - val_acc: 0.7242\n",
            "Epoch 212/350\n",
            "93/93 [==============================] - 15s 157ms/step - loss: 0.2647 - acc: 0.8929 - val_loss: 0.4279 - val_acc: 0.8465\n",
            "Epoch 213/350\n",
            "93/93 [==============================] - 14s 155ms/step - loss: 0.2580 - acc: 0.8989 - val_loss: 0.4493 - val_acc: 0.8410\n",
            "Epoch 214/350\n",
            "93/93 [==============================] - 15s 162ms/step - loss: 0.2644 - acc: 0.8942 - val_loss: 0.4524 - val_acc: 0.8383\n",
            "Epoch 215/350\n",
            "93/93 [==============================] - 15s 166ms/step - loss: 0.2449 - acc: 0.9016 - val_loss: 0.4089 - val_acc: 0.8179\n",
            "Epoch 216/350\n",
            "93/93 [==============================] - 16s 174ms/step - loss: 0.2541 - acc: 0.9023 - val_loss: 0.4072 - val_acc: 0.8492\n",
            "Epoch 217/350\n",
            "93/93 [==============================] - 16s 170ms/step - loss: 0.2414 - acc: 0.9057 - val_loss: 0.7617 - val_acc: 0.8111\n",
            "Epoch 218/350\n",
            "93/93 [==============================] - 17s 181ms/step - loss: 0.2479 - acc: 0.8982 - val_loss: 0.4755 - val_acc: 0.8152\n",
            "Epoch 219/350\n",
            "93/93 [==============================] - 16s 171ms/step - loss: 0.2537 - acc: 0.8962 - val_loss: 0.3603 - val_acc: 0.8505\n",
            "Epoch 220/350\n",
            "93/93 [==============================] - 16s 169ms/step - loss: 0.2589 - acc: 0.8942 - val_loss: 0.3797 - val_acc: 0.8342\n",
            "Epoch 221/350\n",
            "93/93 [==============================] - 17s 187ms/step - loss: 0.2430 - acc: 0.8969 - val_loss: 0.6452 - val_acc: 0.7921\n",
            "Epoch 222/350\n",
            "93/93 [==============================] - 18s 190ms/step - loss: 0.2428 - acc: 0.9050 - val_loss: 0.4444 - val_acc: 0.8370\n",
            "Epoch 223/350\n",
            "93/93 [==============================] - 17s 186ms/step - loss: 0.2340 - acc: 0.9043 - val_loss: 0.4930 - val_acc: 0.8424\n",
            "Epoch 224/350\n",
            "93/93 [==============================] - 17s 181ms/step - loss: 0.2534 - acc: 0.9030 - val_loss: 0.4320 - val_acc: 0.8451\n",
            "Epoch 225/350\n",
            "93/93 [==============================] - 17s 179ms/step - loss: 0.2565 - acc: 0.8935 - val_loss: 0.4102 - val_acc: 0.8315\n",
            "Epoch 226/350\n",
            "93/93 [==============================] - 16s 177ms/step - loss: 0.2381 - acc: 0.9050 - val_loss: 0.4110 - val_acc: 0.8438\n",
            "Epoch 227/350\n",
            "93/93 [==============================] - 18s 189ms/step - loss: 0.2470 - acc: 0.9030 - val_loss: 0.3974 - val_acc: 0.8465\n",
            "Epoch 228/350\n",
            "93/93 [==============================] - 17s 186ms/step - loss: 0.2258 - acc: 0.9158 - val_loss: 0.4365 - val_acc: 0.8492\n",
            "Epoch 229/350\n",
            "93/93 [==============================] - 18s 189ms/step - loss: 0.2471 - acc: 0.9043 - val_loss: 0.5264 - val_acc: 0.8071\n",
            "Epoch 230/350\n",
            "93/93 [==============================] - 17s 183ms/step - loss: 0.2464 - acc: 0.9084 - val_loss: 0.4628 - val_acc: 0.8410\n",
            "Epoch 231/350\n",
            "93/93 [==============================] - 17s 182ms/step - loss: 0.2252 - acc: 0.9063 - val_loss: 0.4135 - val_acc: 0.8370\n",
            "Epoch 232/350\n",
            "93/93 [==============================] - 17s 185ms/step - loss: 0.2402 - acc: 0.9003 - val_loss: 0.4981 - val_acc: 0.8125\n",
            "Epoch 233/350\n",
            "93/93 [==============================] - 17s 185ms/step - loss: 0.2405 - acc: 0.9070 - val_loss: 0.4845 - val_acc: 0.8111\n",
            "Epoch 234/350\n",
            "93/93 [==============================] - 17s 188ms/step - loss: 0.2333 - acc: 0.9104 - val_loss: 0.3937 - val_acc: 0.8533\n",
            "Epoch 235/350\n",
            "93/93 [==============================] - 17s 180ms/step - loss: 0.2032 - acc: 0.9198 - val_loss: 0.4772 - val_acc: 0.8220\n",
            "Epoch 236/350\n",
            "93/93 [==============================] - 16s 176ms/step - loss: 0.2468 - acc: 0.9117 - val_loss: 0.3487 - val_acc: 0.8505\n",
            "Epoch 237/350\n",
            "93/93 [==============================] - 18s 190ms/step - loss: 0.2416 - acc: 0.8949 - val_loss: 0.3708 - val_acc: 0.8628\n",
            "Epoch 238/350\n",
            "93/93 [==============================] - 18s 189ms/step - loss: 0.2673 - acc: 0.8854 - val_loss: 0.4365 - val_acc: 0.8587\n",
            "Epoch 239/350\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "93/93 [==============================] - 18s 197ms/step - loss: 0.2246 - acc: 0.9178 - val_loss: 0.4534 - val_acc: 0.8261\n",
            "Epoch 240/350\n",
            "93/93 [==============================] - 18s 196ms/step - loss: 0.2477 - acc: 0.8962 - val_loss: 0.4213 - val_acc: 0.8465\n",
            "Epoch 241/350\n",
            "93/93 [==============================] - 18s 191ms/step - loss: 0.2449 - acc: 0.9023 - val_loss: 0.3866 - val_acc: 0.8410\n",
            "Epoch 242/350\n",
            "93/93 [==============================] - 18s 190ms/step - loss: 0.2412 - acc: 0.9036 - val_loss: 0.4906 - val_acc: 0.8451\n",
            "Epoch 243/350\n",
            "93/93 [==============================] - 18s 194ms/step - loss: 0.2495 - acc: 0.9043 - val_loss: 0.4443 - val_acc: 0.8438\n",
            "Epoch 244/350\n",
            "93/93 [==============================] - 18s 190ms/step - loss: 0.2258 - acc: 0.9090 - val_loss: 0.4598 - val_acc: 0.8288\n",
            "Epoch 245/350\n",
            "93/93 [==============================] - 18s 189ms/step - loss: 0.2385 - acc: 0.8982 - val_loss: 0.5419 - val_acc: 0.8084\n",
            "Epoch 246/350\n",
            "93/93 [==============================] - 18s 191ms/step - loss: 0.2385 - acc: 0.9077 - val_loss: 0.3857 - val_acc: 0.8478\n",
            "Epoch 247/350\n",
            "93/93 [==============================] - 18s 192ms/step - loss: 0.2338 - acc: 0.9084 - val_loss: 0.4097 - val_acc: 0.8274\n",
            "Epoch 248/350\n",
            "93/93 [==============================] - 18s 194ms/step - loss: 0.2312 - acc: 0.9043 - val_loss: 0.3805 - val_acc: 0.8492\n",
            "Epoch 249/350\n",
            "93/93 [==============================] - 18s 193ms/step - loss: 0.2267 - acc: 0.9111 - val_loss: 0.5608 - val_acc: 0.8179\n",
            "Epoch 250/350\n",
            "93/93 [==============================] - 21s 226ms/step - loss: 0.2280 - acc: 0.9151 - val_loss: 0.4334 - val_acc: 0.8370\n",
            "Epoch 251/350\n",
            "93/93 [==============================] - 21s 223ms/step - loss: 0.2276 - acc: 0.9030 - val_loss: 0.3790 - val_acc: 0.8587\n",
            "Epoch 252/350\n",
            "93/93 [==============================] - 18s 195ms/step - loss: 0.2182 - acc: 0.9131 - val_loss: 0.4094 - val_acc: 0.8560\n",
            "Epoch 253/350\n",
            "93/93 [==============================] - 18s 197ms/step - loss: 0.2348 - acc: 0.9084 - val_loss: 0.3881 - val_acc: 0.8533\n",
            "Epoch 254/350\n",
            "93/93 [==============================] - 18s 194ms/step - loss: 0.2331 - acc: 0.9050 - val_loss: 0.4064 - val_acc: 0.8519\n",
            "Epoch 255/350\n",
            "93/93 [==============================] - 18s 197ms/step - loss: 0.2215 - acc: 0.9117 - val_loss: 0.4376 - val_acc: 0.8247\n",
            "Epoch 256/350\n",
            "93/93 [==============================] - 18s 196ms/step - loss: 0.2291 - acc: 0.9158 - val_loss: 0.5778 - val_acc: 0.8234\n",
            "Epoch 257/350\n",
            "93/93 [==============================] - 18s 190ms/step - loss: 0.2257 - acc: 0.9097 - val_loss: 0.4054 - val_acc: 0.8356\n",
            "Epoch 258/350\n",
            "93/93 [==============================] - 18s 193ms/step - loss: 0.2343 - acc: 0.9070 - val_loss: 0.3456 - val_acc: 0.8628\n",
            "Epoch 259/350\n",
            "93/93 [==============================] - 18s 190ms/step - loss: 0.2603 - acc: 0.9016 - val_loss: 0.3426 - val_acc: 0.8546\n",
            "Epoch 260/350\n",
            "93/93 [==============================] - 18s 195ms/step - loss: 0.2311 - acc: 0.9090 - val_loss: 0.3962 - val_acc: 0.8356\n",
            "Epoch 261/350\n",
            "93/93 [==============================] - 19s 202ms/step - loss: 0.2124 - acc: 0.9117 - val_loss: 0.3797 - val_acc: 0.8614\n",
            "Epoch 262/350\n",
            "93/93 [==============================] - 18s 198ms/step - loss: 0.2193 - acc: 0.9104 - val_loss: 0.7019 - val_acc: 0.8247\n",
            "Epoch 263/350\n",
            "93/93 [==============================] - 18s 199ms/step - loss: 0.2425 - acc: 0.8989 - val_loss: 0.4276 - val_acc: 0.8356\n",
            "Epoch 264/350\n",
            "93/93 [==============================] - 19s 200ms/step - loss: 0.2223 - acc: 0.9171 - val_loss: 0.3520 - val_acc: 0.8641\n",
            "Epoch 265/350\n",
            "93/93 [==============================] - 18s 197ms/step - loss: 0.2146 - acc: 0.9097 - val_loss: 0.3699 - val_acc: 0.8546\n",
            "Epoch 266/350\n",
            "93/93 [==============================] - 18s 192ms/step - loss: 0.2183 - acc: 0.9171 - val_loss: 0.5222 - val_acc: 0.8492\n",
            "Epoch 267/350\n",
            "93/93 [==============================] - 19s 204ms/step - loss: 0.2232 - acc: 0.9124 - val_loss: 0.4788 - val_acc: 0.8261\n",
            "Epoch 268/350\n",
            "93/93 [==============================] - 18s 197ms/step - loss: 0.2236 - acc: 0.9131 - val_loss: 0.4470 - val_acc: 0.8329\n",
            "Epoch 269/350\n",
            "93/93 [==============================] - 18s 191ms/step - loss: 0.1938 - acc: 0.9232 - val_loss: 0.4888 - val_acc: 0.8465\n",
            "Epoch 270/350\n",
            "93/93 [==============================] - 18s 190ms/step - loss: 0.2307 - acc: 0.9131 - val_loss: 0.4370 - val_acc: 0.8587\n",
            "Epoch 271/350\n",
            "93/93 [==============================] - 18s 191ms/step - loss: 0.2390 - acc: 0.9057 - val_loss: 0.4157 - val_acc: 0.8573\n",
            "Epoch 272/350\n",
            "93/93 [==============================] - 18s 189ms/step - loss: 0.2226 - acc: 0.9167 - val_loss: 0.5135 - val_acc: 0.8356\n",
            "Epoch 273/350\n",
            "93/93 [==============================] - 18s 189ms/step - loss: 0.2204 - acc: 0.9158 - val_loss: 0.4337 - val_acc: 0.8465\n",
            "Epoch 274/350\n",
            "93/93 [==============================] - 18s 190ms/step - loss: 0.2184 - acc: 0.9171 - val_loss: 0.4488 - val_acc: 0.8546\n",
            "Epoch 275/350\n",
            "93/93 [==============================] - 18s 193ms/step - loss: 0.2334 - acc: 0.9057 - val_loss: 0.5533 - val_acc: 0.8234\n",
            "Epoch 276/350\n",
            "93/93 [==============================] - 18s 195ms/step - loss: 0.2316 - acc: 0.9070 - val_loss: 0.3938 - val_acc: 0.8546\n",
            "Epoch 277/350\n",
            "93/93 [==============================] - 18s 192ms/step - loss: 0.1965 - acc: 0.9286 - val_loss: 0.4932 - val_acc: 0.8356\n",
            "Epoch 278/350\n",
            "93/93 [==============================] - 18s 190ms/step - loss: 0.2190 - acc: 0.9090 - val_loss: 0.4200 - val_acc: 0.8573\n",
            "Epoch 279/350\n",
            "93/93 [==============================] - 18s 190ms/step - loss: 0.2201 - acc: 0.9144 - val_loss: 0.4380 - val_acc: 0.8533\n",
            "Epoch 280/350\n",
            "93/93 [==============================] - 18s 191ms/step - loss: 0.2075 - acc: 0.9164 - val_loss: 0.4754 - val_acc: 0.8478\n",
            "Epoch 281/350\n",
            "93/93 [==============================] - 18s 189ms/step - loss: 0.2298 - acc: 0.9124 - val_loss: 0.4590 - val_acc: 0.8546\n",
            "Epoch 282/350\n",
            "93/93 [==============================] - 18s 196ms/step - loss: 0.2074 - acc: 0.9218 - val_loss: 0.8333 - val_acc: 0.7622\n",
            "Epoch 283/350\n",
            "93/93 [==============================] - 18s 190ms/step - loss: 0.2200 - acc: 0.9171 - val_loss: 0.5984 - val_acc: 0.8166\n",
            "Epoch 284/350\n",
            "93/93 [==============================] - 18s 191ms/step - loss: 0.2022 - acc: 0.9198 - val_loss: 0.6187 - val_acc: 0.8207\n",
            "Epoch 285/350\n",
            "93/93 [==============================] - 18s 189ms/step - loss: 0.2307 - acc: 0.9131 - val_loss: 0.3716 - val_acc: 0.8492\n",
            "Epoch 286/350\n",
            "93/93 [==============================] - 18s 189ms/step - loss: 0.2230 - acc: 0.9090 - val_loss: 0.4471 - val_acc: 0.8573\n",
            "Epoch 287/350\n",
            "93/93 [==============================] - 18s 189ms/step - loss: 0.2090 - acc: 0.9212 - val_loss: 0.4422 - val_acc: 0.8614\n",
            "Epoch 288/350\n",
            "93/93 [==============================] - 17s 188ms/step - loss: 0.2209 - acc: 0.9104 - val_loss: 0.4395 - val_acc: 0.8519\n",
            "Epoch 289/350\n",
            "93/93 [==============================] - 18s 189ms/step - loss: 0.2362 - acc: 0.9090 - val_loss: 0.4247 - val_acc: 0.8519\n",
            "Epoch 290/350\n",
            "93/93 [==============================] - 18s 189ms/step - loss: 0.2248 - acc: 0.9084 - val_loss: 0.3350 - val_acc: 0.8736\n",
            "Epoch 291/350\n",
            "93/93 [==============================] - 18s 189ms/step - loss: 0.2111 - acc: 0.9171 - val_loss: 0.4696 - val_acc: 0.8478\n",
            "Epoch 292/350\n",
            "93/93 [==============================] - 18s 191ms/step - loss: 0.2226 - acc: 0.9104 - val_loss: 0.6514 - val_acc: 0.7731\n",
            "Epoch 293/350\n",
            "93/93 [==============================] - 18s 189ms/step - loss: 0.2101 - acc: 0.9198 - val_loss: 1.2018 - val_acc: 0.7948\n",
            "Epoch 294/350\n",
            "93/93 [==============================] - 18s 189ms/step - loss: 0.2297 - acc: 0.9009 - val_loss: 0.4005 - val_acc: 0.8478\n",
            "Epoch 295/350\n",
            "93/93 [==============================] - 18s 190ms/step - loss: 0.2361 - acc: 0.9077 - val_loss: 0.4275 - val_acc: 0.8410\n",
            "Epoch 296/350\n",
            "93/93 [==============================] - 18s 190ms/step - loss: 0.1790 - acc: 0.9265 - val_loss: 0.6482 - val_acc: 0.8465\n",
            "Epoch 297/350\n",
            "93/93 [==============================] - 19s 201ms/step - loss: 0.2284 - acc: 0.9104 - val_loss: 0.3967 - val_acc: 0.8519\n",
            "Epoch 298/350\n",
            "93/93 [==============================] - 19s 209ms/step - loss: 0.1998 - acc: 0.9252 - val_loss: 0.4561 - val_acc: 0.8560\n",
            "Epoch 299/350\n",
            "93/93 [==============================] - 20s 214ms/step - loss: 0.2313 - acc: 0.9030 - val_loss: 0.5919 - val_acc: 0.8247\n",
            "Epoch 300/350\n",
            "93/93 [==============================] - 19s 200ms/step - loss: 0.2127 - acc: 0.9151 - val_loss: 0.3859 - val_acc: 0.8601\n",
            "Epoch 301/350\n",
            "93/93 [==============================] - 18s 196ms/step - loss: 0.2188 - acc: 0.9151 - val_loss: 0.3524 - val_acc: 0.8628\n",
            "Epoch 302/350\n",
            "93/93 [==============================] - 18s 191ms/step - loss: 0.2069 - acc: 0.9117 - val_loss: 0.4044 - val_acc: 0.8587\n",
            "Epoch 303/350\n",
            "93/93 [==============================] - 18s 198ms/step - loss: 0.1929 - acc: 0.9225 - val_loss: 0.4774 - val_acc: 0.8370\n",
            "Epoch 304/350\n",
            "93/93 [==============================] - 18s 193ms/step - loss: 0.1955 - acc: 0.9252 - val_loss: 0.3811 - val_acc: 0.8505\n",
            "Epoch 305/350\n",
            "93/93 [==============================] - 18s 191ms/step - loss: 0.2104 - acc: 0.9232 - val_loss: 0.6003 - val_acc: 0.7880\n",
            "Epoch 306/350\n",
            "93/93 [==============================] - 18s 189ms/step - loss: 0.2057 - acc: 0.9225 - val_loss: 0.4008 - val_acc: 0.8560\n",
            "Epoch 307/350\n",
            "93/93 [==============================] - 18s 191ms/step - loss: 0.2180 - acc: 0.9070 - val_loss: 0.3539 - val_acc: 0.8628\n",
            "Epoch 308/350\n",
            "93/93 [==============================] - 18s 189ms/step - loss: 0.1990 - acc: 0.9245 - val_loss: 0.4470 - val_acc: 0.8410\n",
            "Epoch 309/350\n",
            "93/93 [==============================] - 17s 188ms/step - loss: 0.2203 - acc: 0.9185 - val_loss: 0.3901 - val_acc: 0.8587\n",
            "Epoch 310/350\n",
            "93/93 [==============================] - 18s 192ms/step - loss: 0.1962 - acc: 0.9286 - val_loss: 0.3832 - val_acc: 0.8682\n",
            "Epoch 311/350\n",
            "93/93 [==============================] - 18s 189ms/step - loss: 0.2187 - acc: 0.9205 - val_loss: 0.4888 - val_acc: 0.8410\n",
            "Epoch 312/350\n",
            "93/93 [==============================] - 17s 188ms/step - loss: 0.2232 - acc: 0.9212 - val_loss: 0.6145 - val_acc: 0.8315\n",
            "Epoch 313/350\n",
            "93/93 [==============================] - 18s 189ms/step - loss: 0.2012 - acc: 0.9191 - val_loss: 0.6235 - val_acc: 0.8302\n",
            "Epoch 314/350\n",
            "93/93 [==============================] - 18s 189ms/step - loss: 0.2298 - acc: 0.9117 - val_loss: 0.3716 - val_acc: 0.8465\n",
            "Epoch 315/350\n",
            "93/93 [==============================] - 18s 191ms/step - loss: 0.2110 - acc: 0.9178 - val_loss: 0.4818 - val_acc: 0.8274\n",
            "Epoch 316/350\n",
            "93/93 [==============================] - 19s 201ms/step - loss: 0.2123 - acc: 0.9185 - val_loss: 0.7273 - val_acc: 0.8274\n",
            "Epoch 317/350\n",
            "93/93 [==============================] - 19s 205ms/step - loss: 0.2001 - acc: 0.9178 - val_loss: 0.3834 - val_acc: 0.8709\n",
            "Epoch 318/350\n",
            "93/93 [==============================] - 18s 196ms/step - loss: 0.2083 - acc: 0.9225 - val_loss: 0.4863 - val_acc: 0.8655\n",
            "Epoch 319/350\n",
            "93/93 [==============================] - 19s 199ms/step - loss: 0.2244 - acc: 0.9151 - val_loss: 0.4978 - val_acc: 0.8709\n",
            "Epoch 320/350\n",
            "93/93 [==============================] - 19s 201ms/step - loss: 0.2077 - acc: 0.9212 - val_loss: 0.6181 - val_acc: 0.8519\n",
            "Epoch 321/350\n",
            "93/93 [==============================] - 18s 198ms/step - loss: 0.1918 - acc: 0.9198 - val_loss: 0.5195 - val_acc: 0.8641\n",
            "Epoch 322/350\n",
            "93/93 [==============================] - 18s 189ms/step - loss: 0.2439 - acc: 0.9090 - val_loss: 0.4101 - val_acc: 0.8424\n",
            "Epoch 323/350\n",
            "93/93 [==============================] - 18s 192ms/step - loss: 0.1993 - acc: 0.9286 - val_loss: 0.5093 - val_acc: 0.8492\n",
            "Epoch 324/350\n",
            "93/93 [==============================] - 18s 189ms/step - loss: 0.2123 - acc: 0.9200 - val_loss: 0.3751 - val_acc: 0.8519\n",
            "Epoch 325/350\n",
            "93/93 [==============================] - 18s 188ms/step - loss: 0.2027 - acc: 0.9218 - val_loss: 0.4339 - val_acc: 0.8505\n",
            "Epoch 326/350\n",
            "93/93 [==============================] - 18s 191ms/step - loss: 0.2135 - acc: 0.9144 - val_loss: 0.4082 - val_acc: 0.8533\n",
            "Epoch 327/350\n",
            "93/93 [==============================] - 18s 192ms/step - loss: 0.1913 - acc: 0.9259 - val_loss: 0.5058 - val_acc: 0.8668\n",
            "Epoch 328/350\n",
            "93/93 [==============================] - 18s 190ms/step - loss: 0.2135 - acc: 0.9111 - val_loss: 0.4239 - val_acc: 0.8397\n",
            "Epoch 329/350\n",
            "93/93 [==============================] - 18s 188ms/step - loss: 0.1939 - acc: 0.9225 - val_loss: 0.9317 - val_acc: 0.7948\n",
            "Epoch 330/350\n",
            "93/93 [==============================] - 18s 190ms/step - loss: 0.2049 - acc: 0.9178 - val_loss: 0.4590 - val_acc: 0.8573\n",
            "Epoch 331/350\n",
            "93/93 [==============================] - 18s 192ms/step - loss: 0.2277 - acc: 0.9198 - val_loss: 0.4181 - val_acc: 0.8410\n",
            "Epoch 332/350\n",
            "93/93 [==============================] - 18s 190ms/step - loss: 0.1950 - acc: 0.9218 - val_loss: 0.4009 - val_acc: 0.8628\n",
            "Epoch 333/350\n",
            "93/93 [==============================] - 19s 201ms/step - loss: 0.2020 - acc: 0.9218 - val_loss: 0.5348 - val_acc: 0.8478\n",
            "Epoch 334/350\n",
            "93/93 [==============================] - 19s 209ms/step - loss: 0.2172 - acc: 0.9225 - val_loss: 0.3923 - val_acc: 0.8478\n",
            "Epoch 335/350\n",
            "93/93 [==============================] - 18s 197ms/step - loss: 0.1915 - acc: 0.9286 - val_loss: 0.5903 - val_acc: 0.8329\n",
            "Epoch 336/350\n",
            "93/93 [==============================] - 18s 198ms/step - loss: 0.2099 - acc: 0.9232 - val_loss: 1.0890 - val_acc: 0.7962\n",
            "Epoch 337/350\n",
            "93/93 [==============================] - 19s 209ms/step - loss: 0.2129 - acc: 0.9144 - val_loss: 0.3910 - val_acc: 0.8465\n",
            "Epoch 338/350\n",
            "93/93 [==============================] - 19s 201ms/step - loss: 0.2084 - acc: 0.9137 - val_loss: 0.4461 - val_acc: 0.8546\n",
            "Epoch 339/350\n",
            "93/93 [==============================] - 18s 193ms/step - loss: 0.1955 - acc: 0.9191 - val_loss: 0.4051 - val_acc: 0.8533\n",
            "Epoch 340/350\n",
            "93/93 [==============================] - 17s 188ms/step - loss: 0.1712 - acc: 0.9373 - val_loss: 0.4425 - val_acc: 0.8438\n",
            "Epoch 341/350\n",
            "93/93 [==============================] - 18s 189ms/step - loss: 0.1973 - acc: 0.9259 - val_loss: 0.5056 - val_acc: 0.8438\n",
            "Epoch 342/350\n",
            "93/93 [==============================] - 18s 189ms/step - loss: 0.2133 - acc: 0.9158 - val_loss: 0.4383 - val_acc: 0.8261\n",
            "Epoch 343/350\n",
            "93/93 [==============================] - 18s 188ms/step - loss: 0.2074 - acc: 0.9239 - val_loss: 0.4323 - val_acc: 0.8505\n",
            "Epoch 344/350\n",
            "93/93 [==============================] - 17s 188ms/step - loss: 0.2178 - acc: 0.9205 - val_loss: 0.5253 - val_acc: 0.8478\n",
            "Epoch 345/350\n",
            "93/93 [==============================] - 18s 189ms/step - loss: 0.1777 - acc: 0.9367 - val_loss: 0.6318 - val_acc: 0.8451\n",
            "Epoch 346/350\n",
            "93/93 [==============================] - 17s 188ms/step - loss: 0.1998 - acc: 0.9225 - val_loss: 0.6640 - val_acc: 0.8234\n",
            "Epoch 347/350\n",
            "93/93 [==============================] - 17s 187ms/step - loss: 0.2441 - acc: 0.9111 - val_loss: 0.3983 - val_acc: 0.8601\n",
            "Epoch 348/350\n",
            "93/93 [==============================] - 18s 194ms/step - loss: 0.1907 - acc: 0.9218 - val_loss: 0.4965 - val_acc: 0.8288\n",
            "Epoch 349/350\n",
            "93/93 [==============================] - 18s 188ms/step - loss: 0.2040 - acc: 0.9245 - val_loss: 0.5372 - val_acc: 0.8370\n",
            "Epoch 350/350\n",
            "93/93 [==============================] - 18s 189ms/step - loss: 0.2023 - acc: 0.9340 - val_loss: 0.5106 - val_acc: 0.8465\n"
          ]
        }
      ],
      "source": [
        "batch=16\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    rotation_range=40,\n",
        "    width_shift_range=0.3,\n",
        "    height_shift_range=0.3,\n",
        "    shear_range=0.3,\n",
        "    zoom_range=0.3,\n",
        "    horizontal_flip=True,\n",
        "    fill_mode = 'nearest',\n",
        "    channel_shift_range=13,\n",
        "    data_format='channels_last',\n",
        ")\n",
        "\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    train_dir,\n",
        "    target_size=(150, 150),\n",
        "    batch_size=batch,\n",
        "    class_mode='binary',\n",
        ")\n",
        "\n",
        "validation_generator = test_datagen.flow_from_directory(\n",
        "    validation_dir,\n",
        "    target_size=(150, 150),\n",
        "    batch_size=batch,\n",
        "    class_mode='binary')\n",
        "\n",
        "history = model.fit_generator(\n",
        "    train_generator,\n",
        "    steps_per_epoch=1500//batch,\n",
        "    epochs=350,\n",
        "    validation_data=validation_generator,\n",
        "    validation_steps=46) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PRmFuq_3IZvV"
      },
      "outputs": [],
      "source": [
        "model.save('cats_vs_dogs_good853.h5')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2aDLaMexIZvV"
      },
      "outputs": [],
      "source": [
        "model_reloaded = tf.keras.models.load_model('cats_vs_dogs_good85.h5')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wcYWc6ksIZvW"
      },
      "source": [
        "# Task 4 - Visualizing your results"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d5eDpQ3mIZvW"
      },
      "source": [
        "### Visualizing model performance\n",
        "After training the model, we evaluate the loss and accuracy of the model on the test data by plotting training accuracy together with validation accuracy, which will tell us how accurate the model's prediction is compared to the true data. And plotting training loss together with validation loss and its interpretation is based on how well the model is doing in these two sets.\n",
        "\n",
        "The learning curve as seen in the plots below is calculated from the training dataset that gives an idea of how well the model is learning. The validation curve is calculated from a hold-out validation dataset that gives an idea of how well the model is generalizing.\n",
        "\n",
        "We use the visualization to see whether the model overfits. Since the slope in general is not negative, it is not overfitting. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EgnCIThxIZvW",
        "outputId": "acef8e96-a9d3-4ff7-a965-294bbc3e053e"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.engine.sequential.Sequential at 0x15df6dcbd88>"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#visualization of accurazy and loss\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def draw():\n",
        "    acc = history.history['acc']\n",
        "    val_acc = history.history['val_acc']\n",
        "    loss = history.history['loss']\n",
        "    val_loss = history.history['val_loss']\n",
        "\n",
        "    epochs = range(1, len(acc) + 1)\n",
        "\n",
        "\n",
        "    plt.plot(epochs, acc, 'bo', label='Training acc')\n",
        "    plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
        "    plt.title('Training and validation accuracy')\n",
        "    plt.legend()\n",
        "\n",
        "    plt.figure()\n",
        "\n",
        "    plt.plot(epochs, loss, 'bo', label='Training loss')\n",
        "    plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
        "    plt.title('Training and validation loss')\n",
        "    plt.legend()\n",
        "\n",
        "    plt.show()\n",
        "    return model\n",
        "\n",
        "draw()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ear-F5YdIZvX",
        "outputId": "abfbda3b-c1bf-4675-f44c-e23ffa3b6041"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 750 images belonging to 2 classes.\n",
            "WARNING:tensorflow:sample_weight modes were coerced from\n",
            "  ...\n",
            "    to  \n",
            "  ['...']\n",
            "test acc: 0.86277175\n"
          ]
        }
      ],
      "source": [
        "#Test accuracy \n",
        "test_datagen = ImageDataGenerator(rescale=1./255) \n",
        "\n",
        "test_generator = test_datagen.flow_from_directory(\n",
        "    test_dir,\n",
        "    target_size=(150, 150),\n",
        "    batch_size=16,\n",
        "    class_mode='binary')\n",
        "\n",
        "test_loss, test_acc = model.evaluate_generator(test_generator, steps=46)\n",
        "print('test acc:', test_acc)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "81gpedF0IZvX"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.9"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}